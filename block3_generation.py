"""Блок 3: Генерация ответа (LLM)"""
import config
from gigachat_client import get_client

SYSTEM_PROMPT = f"""Ты - AI-куратор курса {config.COURSE_NAME}. Твоя задача - отвечать на вопросы студентов строго на основе предоставленного контекста из материалов курса.

ВАЖНЫЕ ПРАВИЛА:
1. Отвечай ТОЛЬКО на основе предоставленного контекста. НИКОГДА не выдумывай информацию.
2. Если в контексте нет ответа на вопрос - выведи: "В предоставленных материалах курса нет информации по этому вопросу." и сразу закрой чат
3. Указывай модуль/источник информации, если он указан в контексте.
4. Будь дружелюбным и понятным.
5. Если вопрос неясен - уточни, что именно интересует студента.

Формат ответа:
- Начни с прямого ответа на вопрос
- Укажи модуль/источник, если известен
- Будь конкретным и структурированным

НИКОГДА не выдумывай факты, которые не упомянуты в контексте!
"""


async def generate_answer(question: str, context: str) -> str:
    """
    Генерирует ответ на основе вопроса и контекста из RAG.
    
    Args:
        question: Нормализованный вопрос студента
        context: Контекст из релевантных чанков
        
    Returns:
        Ответ для студента
    """
    if not context.strip():
        return "Извините, в базе знаний не найдено информации по вашему вопросу. Попробуйте переформулировать вопрос или обратитесь к куратору."
    
    user_message = f"""Контекст из материалов курса:

{context}

Вопрос студента: {question}

Ответь на вопрос, используя ТОЛЬКО информацию из контекста выше."""
    
    try:
        client = await get_client()
        
        answer = await client.chat_completion(
            system_prompt=SYSTEM_PROMPT,
            user_message=user_message,
            max_tokens=config.MAX_TOKENS,
            temperature=config.TEMPERATURE_GENERATION
        )
        
        return answer.strip()
        
    except Exception as e:
        return f"Произошла ошибка при генерации ответа: {str(e)}"
